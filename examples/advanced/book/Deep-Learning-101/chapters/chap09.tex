% Chapter 9: Convolutional Networks

\chapter{Convolutional Networks}
\label{chap:convolutional-networks}

This chapter introduces convolutional neural networks (CNNs), which are particularly effective for processing grid-structured data like images.

\section{The Convolution Operation}
\label{sec:convolution}

\subsection{Definition}

The \textbf{convolution} operation applies a filter (kernel) across an input:

For discrete 2D convolution:
\begin{equation}
S(i,j) = (I * K)(i,j) = \sum_m \sum_n I(i-m, j-n) K(m, n)
\end{equation}

where $I$ is the input and $K$ is the kernel.

In practice, we often use \textbf{cross-correlation}:
\begin{equation}
S(i,j) = (I * K)(i,j) = \sum_m \sum_n I(i+m, j+n) K(m, n)
\end{equation}

\subsection{Properties}

\textbf{Parameter sharing:} Same kernel applied across spatial locations
\begin{itemize}
    \item Reduces parameters compared to fully connected layers
    \item Enables translation equivariance
\end{itemize}

\textbf{Local connectivity:} Each output depends on local input region
\begin{itemize}
    \item Exploits spatial locality in images
    \item Hierarchically builds complex features
\end{itemize}

\subsection{Multi-Channel Convolution}

For input with $C_{\text{in}}$ channels and $C_{\text{out}}$ output channels:
\begin{equation}
S_{c_{\text{out}}}(i,j) = \sum_{c_{\text{in}}=1}^{C_{\text{in}}} (I_{c_{\text{in}}} * K_{c_{\text{out}}, c_{\text{in}}})(i,j) + b_{c_{\text{out}}}
\end{equation}

\subsection{Hyperparameters}

\textbf{Kernel size:} Typically $3 \times 3$ or $5 \times 5$

\textbf{Stride:} Step size for sliding kernel (stride $s$):
\begin{equation}
\text{Output size} = \left\lfloor \frac{n - k}{s} \right\rfloor + 1
\end{equation}

\textbf{Padding:} Add zeros around input
\begin{itemize}
    \item \textbf{Valid:} no padding
    \item \textbf{Same:} padding to preserve spatial size
    \item \textbf{Full:} maximum padding
\end{itemize}

For "same" padding with stride 1:
\begin{equation}
p = \left\lfloor \frac{k-1}{2} \right\rfloor
\end{equation}

\section{Pooling}
\label{sec:pooling}

\textbf{Pooling} reduces spatial dimensions and provides translation invariance.

\subsection{Max Pooling}

Takes maximum value in each pooling region:
\begin{equation}
\text{MaxPool}(i,j) = \max_{m,n \in \mathcal{R}_{ij}} I(m,n)
\end{equation}

Common: $2 \times 2$ max pooling with stride 2 (halves spatial dimensions).

\subsection{Average Pooling}

Computes average:
\begin{equation}
\text{AvgPool}(i,j) = \frac{1}{|\mathcal{R}_{ij}|} \sum_{m,n \in \mathcal{R}_{ij}} I(m,n)
\end{equation}

\subsection{Global Pooling}

Pools over entire spatial dimensions:
\begin{itemize}
    \item \textbf{Global Average Pooling (GAP):} average over all spatial locations
    \item \textbf{Global Max Pooling:} maximum over all spatial locations
\end{itemize}

Useful for reducing parameters before fully connected layers.

\subsection{Alternative: Strided Convolutions}

Modern architectures sometimes replace pooling with strided convolutions to learn downsampling.

\section{CNN Architectures}
\label{sec:cnn-architectures}

\subsection{LeNet-5 (1998)}

Early CNN for digit recognition:
\begin{itemize}
    \item Conv $\to$ Pool $\to$ Conv $\to$ Pool $\to$ FC $\to$ FC
    \item Used sigmoid/tanh activations
    \item ~60K parameters
\end{itemize}

\subsection{AlexNet (2012)}

Breakthrough on ImageNet:
\begin{itemize}
    \item 8 layers (5 conv, 3 FC)
    \item ReLU activation
    \item Dropout regularization
    \item Data augmentation
    \item ~60M parameters
\end{itemize}

\subsection{VGG Networks (2014)}

Simplified architecture with small filters:
\begin{itemize}
    \item Only $3 \times 3$ convolutions
    \item Deeper networks (VGG-16, VGG-19)
    \item $2 \times 2$ max pooling
    \item ~138M parameters (VGG-16)
\end{itemize}

\subsection{ResNet (2015)}

Introduced \textbf{residual connections}:

\begin{equation}
\vect{y} = \mathcal{F}(\vect{x}, \{\mat{W}_i\}) + \vect{x}
\end{equation}

where $\mathcal{F}$ is the residual mapping.

Benefits:
\begin{itemize}
    \item Enables very deep networks (50, 101, 152 layers)
    \item Addresses vanishing gradient problem
    \item Identity mappings facilitate optimization
    \item Won ImageNet 2015
\end{itemize}

\textbf{Bottleneck block:}
\begin{itemize}
    \item $1 \times 1$ conv (reduce dimensions)
    \item $3 \times 3$ conv
    \item $1 \times 1$ conv (restore dimensions)
    \item Skip connection
\end{itemize}

\subsection{Inception/GoogLeNet (2014)}

\textbf{Inception modules} apply multiple filter sizes in parallel:
\begin{itemize}
    \item $1 \times 1$, $3 \times 3$, $5 \times 5$ convolutions
    \item $3 \times 3$ max pooling
    \item Concatenate outputs
    \item $1 \times 1$ convolutions for dimension reduction
\end{itemize}

\subsection{MobileNet and EfficientNet}

\textbf{MobileNet:} Efficient architecture for mobile/edge devices
\begin{itemize}
    \item Depthwise separable convolutions
    \item Reduces computation and parameters
\end{itemize}

\textbf{EfficientNet:} Compound scaling method
\begin{itemize}
    \item Balances depth, width, and resolution
    \item State-of-the-art efficiency
\end{itemize}

\section{Applications of CNNs}
\label{sec:cnn-applications}

\subsection{Image Classification}

Task: Assign label to entire image.

Architecture:
\begin{itemize}
    \item Convolutional layers extract features
    \item Pooling reduces dimensions
    \item Fully connected layers for classification
    \item Softmax output
\end{itemize}

\subsection{Object Detection}

Task: Localize and classify objects in images.

\textbf{Region-based methods (R-CNN family):}
\begin{itemize}
    \item R-CNN: region proposals + CNN features
    \item Fast R-CNN: end-to-end training
    \item Faster R-CNN: learned region proposals
    \item Mask R-CNN: adds instance segmentation
\end{itemize}

\textbf{Single-shot methods:}
\begin{itemize}
    \item YOLO (You Only Look Once): real-time detection
    \item SSD (Single Shot Detector): multi-scale detection
\end{itemize}

\subsection{Semantic Segmentation}

Task: Assign class label to each pixel.

\textbf{FCN (Fully Convolutional Networks):}
\begin{itemize}
    \item Replace FC layers with convolutions
    \item Upsampling to recover spatial resolution
\end{itemize}

\textbf{U-Net:}
\begin{itemize}
    \item Encoder-decoder architecture
    \item Skip connections between encoder and decoder
    \item Popular in medical imaging
\end{itemize}

\textbf{DeepLab:}
\begin{itemize}
    \item Atrous (dilated) convolutions
    \item Atrous spatial pyramid pooling (ASPP)
    \item Conditional random fields (CRF) post-processing
\end{itemize}

\subsection{Image Generation}

\textbf{Style Transfer:} Transfer artistic style between images

\textbf{Super-Resolution:} Increase image resolution

\textbf{Image-to-Image Translation:} Convert between image domains (e.g., pix2pix, CycleGAN)

\subsection{Beyond Images}

CNNs are also effective for:
\begin{itemize}
    \item Video analysis (3D convolutions)
    \item Audio/speech processing (1D convolutions on spectrograms)
    \item Time series forecasting
    \item Graph-structured data (graph convolutions)
\end{itemize}
